%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{graphicx} % for png files
\graphicspath{{img/}}
\usepackage{multirow}
%\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Detection of design pattern : A systematic mapping study}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Pierre Gerard, Alexandre St-Louis Fortier, Badr Mai and Houari Sahraoui \\
Département IRO \\
Université de Montréal, Montreal, Canada \\
\{gerardpi,stlouial,badr.mai,sahraouh\}@iro.umontreal.ca
% <-this % stops a space
%\thanks{*This work was not supported by any organization}% <-this % stops a space
%\thanks{$^{1}$H. Kwakernaak is with Faculty of Electrical Engineering, Mathematics and Computer Science,
 %       University of Twente, 7500 AE Enschede, The Netherlands
  %      {\tt\small h.kwakernaak at papercept.net}}%
%\thanks{$^{2}$P. Misra is with the Department of Electrical Engineering, Wright State University,
   %     Dayton, OH 45435, USA
    %    {\tt\small p.misra at ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

% Place holder
Design patterns are important because they help solving recurring design problems in software engineering. The identification of those patterns can be helpful to maintain and understand the code especially in large systems. Interest in design patterns detection has grown in the last decade. Despite the huge interest given to design patterns detection, there is no reliable or formal method for this matter.
We conducted a systematic mapping study on design patterns detection by querying multiple sources to get articles that are relevant to our study. 403 articles between 2000 and 2015 were considered.
The main purpose of the study is to know which methods and techniques are used to detect design patterns.
The result help us understand how those techniques work and which type of pattern is detected the most.



\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

% Design patterns are a 

Design partterns are best pratices to recurring design problems first proposed
by the Gang of Four in their seminal book.

(Some study author) have been able to show that the presence of design patterns,
if correctly presented, can help developpers better understand a piece of
software [citation needed].
It would therefore be desirable to be able to automatically extract those
design patterns and present them in a digestible format.

Detection of design patterns in software has been a relatively active research
interest of the past decade in software engineering.
Proposed methods of automatic detection aims in part to facilitate the work of
developers in understanding a piece of software through reverse engineering.

However, design pattern detection tools are still not featured in the typical
programmer toolbox.

No studies have been conducted to analyze the trends of the field.

This paper presents a systematic mapping study on design pattern detection
methods.
It is organized as follows: 
 The first section explains the systematic mapping process
 The second section explains the selection process results
 The third one deals analyses the study results
 The article then continues with the limitations of our study
 It finishes with related work. 

% pourquoi la detection

% pourquoi ce systematic mapping

\section{SYSTEMATIC MAPPING PROCESS}

In this section, we discuss step by step how we conducted our systematic
mapping study.
We have followed the process defined by Petersen et al \cite{c1}. 

\subsection{Research question}

The main goal of this paper is to determine the quantity and trends of research
in design pattern detection and the possibility of proposed detection methods.
% Our classification scheme doesn't really allow us to take any position
% relative to the quality of the methods. At most, it provide a sensible
% evaluation of the field

% Pierre : oui par qualité je voulais dire ce qu'il est capable de detecter : possibility ?

\begin{itemize}
	\item \textbf{RQ1} : How mature is research on the subject of design pattern detection ?
	\item \textbf{RQ2} : What methods of design pattern detection are used ?
\end{itemize}


\subsection{Data source and queries}

We decided to query only one database, Scopus \cite{c2}, that claims to be the
largest abstract and citation database of peer-reviewed literature.
It indexes the main Computer Science databases : Springer, IEEE, ACM and
others.
The main advantage of using Scopus is that it provides a functionality to
export the result of a search query on its database.
Some of those exported results would not have been easily obtainable on some
publishers search engines that do not provide an export functionality.
Consequently, Scopus was used as a mostly as a search and export portal over the
relevant publications, greatly reducing the effort needed to extract the
initial articles set. 

From the two research questions we tried to maximize the number of publications
found on the subject.
It was decided to run our query only on the title, the abstract and the keywords of
each article. 
Our query was relatively simple,  "design pattern" and "detection" had to be present
in the searched part of an article.
To maximize the number of publications found, we considered variations of both part
of our query in the form of synonyms and words sharing the same root.
Therefore, we have extended our query to not only match "design pattern" but "design motif" as well. In the same vein, instead of only "detection" and its variations
"identification" and "recognition", we queried their contracted forms "detect*",
"ident*", and "recogni*".

To limit the scope of our research only the articles published between the years
2000 and 2015 have been included. 

We have also limited our research to the field of computer science and
engineering.


\subsection{Screening}

The aim of screening is to select papers relevant to design pattern detection.
For that purpose, we used an exclusion scheme containing four criteria:

\begin{enumerate}
  \item \textbf{Not a contribution in software engineering}: 
    This criterion was used to exclude articles not relevant to the domain and
    software engineering articles that are nothing more than mere use case
    reports.
  \item \textbf{Not a full conference or research paper}:
    This criterion was used to exclude small research papers
  \item \textbf{Not about software design patterns}:
    This criterion excludes articles where the main contribution is not about
    software design patterns,
    % TODO: We cannoct base our exclusion to DP defined by the GoF because we
    % have a class for other pattern type.
    % Limiting to software design patterns would be enough
  \item \textbf{The main contribution of the paper is not about a method of detecting design patterns}:
    This criterion was used to exclude benchmarks and other analysis whose main
    purposes are not a method of design pattern detection.
\end{enumerate}

The rejection criteria are ordered: an article that doesn't satisfy a specific
criteron cannot be rejected for a succeeding one.
Hence, the lowest applicable exclution criteron should always be the cause of
rejection.

\subsection{Classification scheme}

To determine a relevant classification scheme we mainly used three things.
The first was our general knowledge of the field on the subject and the matter
ensuing.
The second was the information extracted during the screening process that
allowed us to identify the most important classification items.
The last one was advices on which are the important point from a senior
researcher who used to work on design pattern detection techniques.

All of that leaded us to seven main categories.

\begin{itemize}
  \item \textbf{Detection strategy}:
    This determine the means on which the detection is based.
    Possible values: Artificial intelligence, Logic/Formalization, Graph,
    Metric, Automata, Instrumentation/profiling and Others.

  \item \textbf{Language dependence}:
    This category aims to classify detection methods on whether it is dependent
    on the language or not. 
    Possible values: Dependant or Independant
% TODO: This  specifies if the detection is langage dependent or independent,

  \item \textbf{Analysis type}:
    This determine if a detection techniques use a static, dynamic or hybrid
    approach.
    Possible values: Static, Dynamic and Hybrid.

  \item \textbf{Validation method}:
    This specifies the type of scientific validation methods the article's 
    authors used for a detection method.
    Possible values: Benchmark, Case study, Experiment, Survey, Other and
    None.
    
  \item \textbf{Detection Level}
    This define on which level the detection method work : execution, source
    and model.
    It could be more than one level for a single method of detection.
    Possible values: Execution, Source and Model.

  \item \textbf{Detected pattern types}:
    This characterizes the type of design pattern a specific detection method
    can manage.
    The possible values for this category are Creational, Behavioral,
    Structural and Not specified.

  \item \textbf{Pattern detection generality}:
    This determine if a method is made to detect a single pattern or more than
    one pattern.
    Possible values: Specific, General.
\end{itemize}



\subsection{Systematic map}
The systematic mapping 

\section{SELECTION PROCESS RESULTS}

\textit{Fig. 1} illustrates the flow of information at each phase of the study.

\subsection{Selection}

As per the systematic mapping study process, we started with a sizeable initial
article set, reducing its size at each phase as not relevant articles were rejected.

Our initial article set was made of 403 articles returned by the query on Scopus
database.

Of those articles, we found two duplicates that were immediately removed from
the set of articles to analyze, which brought down the number of articles for
screening to 401.

\subsection{Screening}

After having queried the database and removed the duplicates, we exported the
results found as a .csv file and proceeded to the screening.

As we were three authors to work on the screening, we created three pairs
of evaluators and distributed the articles evenly between them.

The screening phase was done with the help of a spreadsheet where a column was
created for each evaluator.
Each evaluator was instructed to rate each article he's been assigned with a number
from 1 to 5, where 5 corresponds to the acceptation of the article and numbers below
to the applicable rejection criterion as defined in the previous section.
To prevent the rejection of relevant article, raters were instructed to accept
any article susceptible of being relevant with the afterthought that it could be
rejected after a complete reading.

Each article was rated according to the reading of its title and its abstract by
individual evaluator.

\begin{figure*}[tb]
 \centering
 \includegraphics[scale=0.5]{flow.png}
 \caption{Flow of information}
\end{figure*}

\begin{figure}
 \centering
  \begin{tabular}{ ccc }
   \bf Group & \bf \# of articles & \bf Cohen's kappa \\
   \hline {}
   1 & 132 & 0.88 \\
   2 & 133 & 0.66 \\
   3 & 133 & 0.91 \\
 \end{tabular}
 \caption{Cohen's Kappa coefficients}
\end{figure}

For each article, we ensured that articles were rated consistently amongst the
evaluators.

Disagreement in the rating of article inside a pair were firstly dealt with a
reconsidaration of the rating by each individual according to the arguments of
his opposing rater.
In the case of unresolved disagreement, we brought our case before a senior
researcher that published in the studied field who would instruct us over the final
decision.
If even he couldn't settle de disagreement, the article was included to possibly be
excluded at a later point.

94 articles passed our exclusion scheme and thus the screening phase. 



\subsubsection{Cohen's kappa coefficient}
Cohen's kappa coefficient is a measure of the inter-agreement between two rater
over the classification of a set of values.
A high coefficient value is indicative of a relative agreement between a pair
of raters.

We calculated inter-rater agreement Cohen's kappa coefficient over the
rejection and acceptation of each articles, which gaves us an average
coefficient of 0.81.
Individual results for each pair of evaluators is given in \textit{Fig. 2}
alongside the number of articles assigned to each one.

It is usually said that a Cohen's kappa coefficient of more than $0.7$ indicate
a good agreement \cite{c3}.


\subsection{Classification}

Considering the number of articles that passed the screening phase



\section{STUDY RESULTS}

\subsection{Yearly distribution}

The yearly distribution gives us an interesting picture of the field.
Interest in design patterns detection technique started in the early
2000 and that interest plateaued between the years 2005 and 2013.
Since then the field lost steam with a number of publication per years
roughly equivalent to those at its inception.

This could indicate either that the field is mature and that research avenues
have been exhaused, that the field currently hit a roadblock, or that interest
is fading due to a lack of interest in the need for design pattern detection
tools.

\begin{figure}
  \centering
  \includegraphics[scale=0.450]{year_distribution.png}
  \caption{}
\end{figure}


\begin{figure}
  \centering
   \small
   \begin{tabular}{ lll }
    \bf Category & \bf Class & \bf \# of articles \\
    \hline
    \multirow{7}{*}{Detection Strategy}
    & \multicolumn{1}{l}{AI}           & \multicolumn{1}{l}{11} \\
    & \multicolumn{1}{l}{Logic}        & \multicolumn{1}{l}{19} \\
    & \multicolumn{1}{l}{Graph}        & \multicolumn{1}{l}{13} \\
    & \multicolumn{1}{l}{Metric}       & \multicolumn{1}{l}{7} \\
    & \multicolumn{1}{l}{Automata}     & \multicolumn{1}{l}{1} \\
    & \multicolumn{1}{l}{Instr./Prof.} & \multicolumn{1}{l}{9} \\
    & \multicolumn{1}{l}{Pattern Matching}
                                       & \multicolumn{1}{l}{8} \\
    & \multicolumn{1}{l}{Others}       & \multicolumn{1}{l}{19} \\
    \hline
    \multirow{2}{*}{\textbf{Language Dependence}}
    & \multicolumn{1}{l}{Dependant}    & \multicolumn{1}{l}{37} \\
    & \multicolumn{1}{l}{Independent}  & \multicolumn{1}{l}{16} \\
    \hline
    \multirow{3}{*}{\textbf{Analysis Type}}
    & \multicolumn{1}{l}{Static}       & \multicolumn{1}{l}{25} \\
    & \multicolumn{1}{l}{Dynamic}      & \multicolumn{1}{l}{13} \\
    & \multicolumn{1}{l}{Hybrid}       & \multicolumn{1}{l}{17} \\
    \hline
    \multirow{3}{*}{Detection Level}
    & \multicolumn{1}{l}{Source}       & \multicolumn{1}{l}{44} \\
    & \multicolumn{1}{l}{Model}        & \multicolumn{1}{l}{8} \\
    \hline
    \multirow{2}{*}{Detection generality}
    & \multicolumn{1}{l}{Specific}     & \multicolumn{1}{l}{40} \\
    & \multicolumn{1}{l}{General}      & \multicolumn{1}{l}{11} \\
    \hline
    \multirow{4}{*}{Detected Pattern Types}
    & \multicolumn{1}{l}{Creational}  & \multicolumn{1}{l}{22} \\
    & \multicolumn{1}{l}{Structural}   & \multicolumn{1}{l}{33} \\
    & \multicolumn{1}{l}{Behavior}    & \multicolumn{1}{l}{37} \\
    & \multicolumn{1}{l}{Other/Not Specified}
                                       & \multicolumn{1}{l}{12} \\
    \hline
    \multirow{6}{*}{Validation Method}
    & \multicolumn{1}{l}{Benchmark}    & \multicolumn{1}{l}{7} \\
    & \multicolumn{1}{l}{Case Study}   & \multicolumn{1}{l}{37} \\
    & \multicolumn{1}{l}{Experiment}   & \multicolumn{1}{l}{8} \\
    & \multicolumn{1}{l}{Survey}       & \multicolumn{1}{l}{0} \\
    & \multicolumn{1}{l}{Other}        & \multicolumn{1}{l}{1} \\
    & \multicolumn{1}{l}{None}         & \multicolumn{1}{l}{8}
   \end{tabular}
   \caption{Classification Results - Categories whose values represent disjoint sets are presented in bold}

\end{figure}

\subsection{Publication Venue Distribution}
% Need a graphic for article by publishers.


\subsection{Detection Strategy}

Most of the detection strategies used fall either in the 
\textit{logic/formalization} or \textit{other} class.
The first one was probably overly broad since it included any solution using
inference rules engines, formalization and semantic web ontologies.
Surprisingly, the latter strategy was the focus of many articles.

Another strong 


\subsection{Analysis Type}

Design pattern detection can be done either statically, dynamically or in
a combination of both.

A little bit less than half of the articles favoured a static approach to the
recognition of design motifs.





\subsection{Detected Pattern Types}

The Gang of Four identified three design pattern types: creational,
behavioural and structural patterns.

Due to the nature of each pattern types, our intuition would dictate that
structural patterns should be easier to detect than behavioral patterns and
that the later are easier than creational patterns (citation needed). 
It was expected that this ordering would appear in the number of articles
associated with each pattern types. 
However, we can see that the detection of behavioral patterns has been the
subject of more articles than the two others.


This can be explained either by the fact that structural design patterns
detection is considered as an easy problem, thus less likely to be the main
focus of a research paper or by the possibility that behavioral design
patterns are in fact easier to detect than structural ones.
We believe the first possibility to be more likely.

Of interest is the relation between the type of analysis and the type of
patterns detected. \textit{Fig. 5} and \textit{Fig. 6}
respectively presents the distribution of the number of articles and their
proportion in this relation. 


\begin{figure}
 \centering
 \begin{tabular}{llll}
             & Static & Dynamic & Hybrid \\
 \hline
 Structural  & 18 & 7 & 8 \\
 Behavioural & 17 & 7 & 13 \\
 Creationnal & 14 & 1 & 7 \\
 Other       & 3 & 5 & 4 \\
 \end{tabular}
 \caption{Analysis type according to detected pattern type}
\end{figure}

\begin{figure*}[tb]
 \centering
 \includegraphics[scale=0.7]{analysis_v_pattern.png}
 \caption{Analysis type distribution per detected pattern type}
\end{figure*}





\subsection{Language dependance}
The main focus of this category was to identify the existance of language
independant solutions to the detection of design patterns.

To identify truly generic detection methods, proposed solutions requiring a
frontend to implement have been classified as being dependant on the source
language. 

The majority of techniques are language dependent and the most used 
languages are Java and C++, but those detection methods can be easily converted
to other languages by a simple modification of a font-end.


\subsection{Detection Level}

We found out that almost all of design patterns detection methods 
identify the patterns at the source code level, though, the detection could
be done on multiple levels.

When detection was done at multiple level, more often than not it was at both
the source and execution level.



\subsection{Detection generality}

This category was used to expose specific pattern detection methods.
As expected, papers tend to present detection method for detecting patterns
in general.

Systems based on rules are examples of general technique for which 
an inference engine is able to handle any patterns it has a rule for.
Di Martino and Esposito[40] presented a technique where ODOL is used
to describe the structural aspects of patterns.

Some papers worth noting presents specifics ways to detect particular patterns.

Heričko and Beloglavec[355] presents a way of identifying
composite design pattern, not to be confused with the definition of the 
composite pattern defined by the GoF, here, composite pattern corresponds to the
composition of atomic design pattern (the Model View Controler pattern being an
example of a composite pattern).

Ren and Zhao[80] used and hybrid analysis based on OWL, an ontology system,
to recover instances candidates of Observer pattern followed by a dynamic
analysis to accept or reject the recovered candidates.


\subsection{Validation Methods}

Case studies are the most common methods of validation with a weak rate of
experiences and a total absence of true benchmarks.

Researchers in the Java world seem to have agreed on the use of JHotDraw,
JRefactory, JUnit, and AWT for evaluation.
However, while JHotDraw, a software known for its internal use of design
pattern, is the most frequently used, there is no clear benchmark.

Very few articles have taken the time to do a proper comparative evaluation.
De Lucia et al.[151] did an excellent work in that regard.
They compared their approach to existing tools and P-MARt's knowledge base
of pattern instances in JHotDraw and JRefactory, thus building a
strong case for their technique.
Unfortunately, most technique seem to be evaluated in a vacuum which makes it
difficult to compare their efficiency.

Also, because most technique are language dependant, comparative studies are
often times limited to case study in one language.
Again, few articles try to present results taken from software written in
different languages.
This is problematic because no common ground for comparison exists between
technique whose evaluation is done on software written in different languages.
Gueheneux and Antoniol[255] presented an extensive evaluation of DeMIMA on
five open source Java projects and 33 industrial component written in C++.
While the use of closed source components is in itself problematic, the
evaluation of their system on both Java and C++ programs is noteworthy.

%TODO: citation needed
Other articles, due to the work involved in manually identifying instances of
design pattern for evaluation, have simply choosen to compare their result to
the output of existing tools.
Even if some use multiple tools to cross-check the identified pattern instances,
we believe such evaluation methods are flawed since we don't know how well
those tools perform due to the absence of a standard benchmark.
The existence of pattern repository like P-MARt should supersede those
validation techniques.

We have also noticed that there is no validation standards, there is a lot
of tools that can detect patterns, but since there are no standards 
none of those tools can be truly reliable.

All these issues seem to indicate a lack of maturity of the field of design
pattern detection.
At least, more work is necessary to compare the different techniques.


\section{Study limitations}

\subsection{Selection Bias}

A possible limitation of our studies is the selection of a unique source for 
the articles in Scopus.
This was done to facilitate our work in the extraction of relevant articles
since Scopus offers to export the results of a search query on its database.
It has been assumed that it does an exhaustive indexing of the journals
and conferences it references and that those sources includes most of the
relevant publications that covers software design pattern detection.
To mitigate the possibility of missing relevant articles we made sure that
Scopus indexes the big venues of software engineering (ACM, Springer and IEEE).

\subsection{Screening}

There is a possibility for relevant articles to have been excluded at the
screening level due to a non representative title and abstract.
We believe the possibility to be unlikely since each article was screened by
two reviewers and that if the article had a possibly misleading title, it would
be rejected after a complete reading done before the classification phase.

As it can be seen with Cohen's kappa coefficient of the second screening group,
there were some disagreement related to the inclusion or the exclusion of some
articles.
Most of those disagreement comes from different views of what constitute a
software engineering papers and the fact that many fields have adopted the
concept of design patterns.
Even if the Cohen's kappa coefficient can be considered somewhat low for the
second group, we are confident with our screening since most disagreement have
been resolved by an experienced researcher in the field if a pair of reviewers
couldn't reach a consensus.


\subsection{Classification}

The distribution of articles between the reviewers may seem arbitrary in since it is not evenly distributed.
In fact one reviewer had two less articles to read.
This difference is due to an error when we compiled the articles that passed
the screening phase where one article was featured twice.
Since the remaining number of articles was not divisible by three, this same
reviewer had already one less article to read.
We believe this error has no effect on the overall result.

At first, we defined the detection level to be a disjoint classification
category.
However during the classification phase of our study, we stumbled upon
unforeseen cases where the detection was done at two levels.
We had to change the classification scheme to allow those cases.



\section{Related works}

While no other systematic mapping study have been done on design pattern
detection technique, other reseachers attempted to address the problems
present in the field.

Pettersson, Lowe, and Nivre[190] identified a lack of proper evaluation of 
design pattern detection technique, in part due to the absence of an accepted
standard benchmark.
This problem has been observed in our evaluation of the domain in that most
articles evaluates their algorithms with case studies that are hardly
comparable.
They identified the existance of evaluation gold standard in JHotDraw, Swing
and AWT  and pushed for the definition of a standard benchmark made of varied
systems (language, size, etc.)



\section{CONCLUSIONS}

A conclusion section 



\addtolength{\textheight}{-12cm}   

% This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}

Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}

Acknowledgment


\begin{thebibliography}{99}

\bibitem{c1} K. Petersen, R. Feldt, S. Mujtaba, and M. Mattsson, “Systematic mapping studies in software engineering,” in Proc. of the 12th Int. Conf. on Eval. and Asses. in Soft. Eng., ser. EASE’08. Swinton, UK, UK: British Computer Society, 2008.

\bibitem{c2} www.scopus.com

\bibitem{c3} Landis, J. Richard, and Gary G. Koch. "The measurement of observer agreement for categorical data." biometrics (1977): 159-174.









\end{thebibliography}




\end{document}
